{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "a5423f80_470922d5",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 15
      },
      "lineNbr": 0,
      "author": {
        "id": 1002504
      },
      "writtenOn": "2025-05-27T19:43:45Z",
      "side": 1,
      "message": "Main thing is lots of allocation in the hot path. If you want to instrument to find any further allocations I missed during review, the following snippet is helpful but not for any kind of production use...\n\nvoid *operator new(size_t size)\n{\n    void *p \u003d malloc(size);\n    if (!p) throw std::bad_alloc;\n    std::cout \u003c\u003c \"allocated \" \u003c\u003c size \u003c\u003c std::endl;\n    std::cout \u003c\u003c std::stacktrace::current();\n    return p;\n}\n\nvoid operator delete(void *p)\n{\n    free(p);\n}",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "0a0a32f0_be68193b",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 37,
      "author": {
        "id": 1002504
      },
      "writtenOn": "2025-05-27T19:22:23Z",
      "side": 1,
      "message": "You should be able to avoid holding a raw socket here, and let boost handle it completely. Something along the lines of:\n\n\nboost::asio::generic::datagram_protocol protocol {AF_MCTP, 0};\nsock \u003d boost::asio::basic_datagram_socket\u003cboost::asio::generic::datagram_protocol\u003e{ctx, protocoll};",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "409c6dde_22ad26bd",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 37,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "0a0a32f0_be68193b",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "59410004_a3558cd6",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 58,
      "author": {
        "id": 1002504
      },
      "writtenOn": "2025-05-27T19:43:45Z",
      "side": 1,
      "message": "you should be able to avoid this completely if you just use the boost socket everywhere and specify blocking vs non blocking APIs when appropriate, or just use the non blocking API\u0027s throughout.",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "c9659ba7_306c5562",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 58,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "59410004_a3558cd6",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "a767bbd1_08ef0bd7",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 73,
      "author": {
        "id": 1002504
      },
      "writtenOn": "2025-05-27T19:22:23Z",
      "side": 1,
      "message": "Can we have the caller pass in a buffer to place the response into, rather than forcing an allocation. They will generally have a better idea of the expected size and can handle that more elegantly than we can in this class.",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "ceb18aa4_e6b9ab14",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 73,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "a767bbd1_08ef0bd7",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "c57b7298_7213ab93",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 83,
      "author": {
        "id": 1002504
      },
      "writtenOn": "2025-05-27T19:22:23Z",
      "side": 1,
      "message": "Any reason we\u0027re not using boost::system::error_code? it automatically does stringification of the error codes for you and doesn\u0027t rely on \"which typing\"",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "489b1528_891993f0",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 83,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "c57b7298_7213ab93",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "c78d661b_28cffef6",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 109,
      "author": {
        "id": 1002504
      },
      "writtenOn": "2025-05-27T19:22:23Z",
      "side": 1,
      "message": "nit, this is overly verbose. you can just take sizeof(reqHdr), which will avoid dual maintenance if this type ever changes. Same feedback on line 116.",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "1e06a950_f6bec4dd",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 109,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "c78d661b_28cffef6",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "caf17d5f_7b6d3129",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 136,
      "author": {
        "id": 1002504
      },
      "writtenOn": "2025-05-27T19:22:23Z",
      "side": 1,
      "message": "Don\u0027t force your clients to have allocated memory, this can and probably should be a std::span\u003cstd::uint8_t\u003e or similar.",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "7256884d_5a52af03",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 136,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "caf17d5f_7b6d3129",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "800d0af1_e1f9f6ff",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 137,
      "author": {
        "id": 1002504
      },
      "writtenOn": "2025-05-27T19:22:23Z",
      "side": 1,
      "message": "this may (likely will) invoke malloc/new on copy. Consider using std::move_only_function if possible.",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "f096a1ce_f7d4f34d",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 137,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "800d0af1_e1f9f6ff",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "4c61c0cb_0e5ce790",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 160,
      "author": {
        "id": 1002504
      },
      "writtenOn": "2025-05-27T19:22:23Z",
      "side": 1,
      "message": "why not use the boost handlers for this? something along the lines of\n\nstruct sockaddr_mctp addr; // do your initialization\nboost::asio::generic::datagram_protocol::endpoint ep(\u0026addr, sizeof(addr), AF_MCTP);\n\nand later, \n\nsock.send_to(reqMsg.data(), reqMsg.size(), ep);\n\nThat way you don\u0027t have to worry about weirdness around size differences between the sockaddr_mctp and the storage type sockaddr, boost will take care of it for you.\n\nYou may also want to consider using the non blocking version of this call so your thread can do meaningful work while this is being sent. This may require copying of same data, but for many mctp packets, copying data that\u0027s potentially already in the cache is quite cheap, especially compared to blocking io.",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "c361359b_040c17fc",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 160,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "4c61c0cb_0e5ce790",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "bd30029d_acd3392c",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 184,
      "author": {
        "id": 1002504
      },
      "writtenOn": "2025-05-27T19:22:23Z",
      "side": 1,
      "message": "do we expect for this client to be handling multiple messages simultaneously? if not, we can avoid allocating a vector for this and just cache the response. If we have a reasonable upper bound on concurrent messages, consider using something similar to a boost::containers::static_vector of array\u0027s to avoid malloc/new as well as the cache misses involved. BMC\u0027s generally have a decent amount of ram to spare for stuff like this, especially if the message sizes are in the 10s or hundreds of bytes.",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "17e51579_c9673181",
        "filename": "src/nvidia-gpu/MctpRequester.cpp",
        "patchSetId": 15
      },
      "lineNbr": 184,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "bd30029d_acd3392c",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "2fe1b975_e8495239",
        "filename": "src/nvidia-gpu/MctpRequester.hpp",
        "patchSetId": 15
      },
      "lineNbr": 22,
      "author": {
        "id": 1000056
      },
      "writtenOn": "2025-05-27T17:00:50Z",
      "side": 1,
      "message": "Commit wide comment - let\u0027s remove doxygen doc - other dbus sensor apps dont have it and it\u0027s hard to keep correct...",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "e9bb5182_e3cc4b13",
        "filename": "src/nvidia-gpu/MctpRequester.hpp",
        "patchSetId": 15
      },
      "lineNbr": 22,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-29T14:42:29Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "2fe1b975_e8495239",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "af03c584_2c1b3f04",
        "filename": "src/nvidia-gpu/NvidiaGpuMctpVdm.cpp",
        "patchSetId": 15
      },
      "lineNbr": 58,
      "author": {
        "id": 1002504
      },
      "writtenOn": "2025-05-27T19:22:23Z",
      "side": 1,
      "message": "similar to previous comments about interfaces that enforce memory allocation, please use a known owning view like std::span. This goes for pretty much any \"public\" interface that takes a vector but really just needs a view of some bytes in contiguous memory.",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "d0de94fc_8d589a05",
        "filename": "src/nvidia-gpu/NvidiaGpuMctpVdm.cpp",
        "patchSetId": 15
      },
      "lineNbr": 58,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "af03c584_2c1b3f04",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "1c9c9028_d3718bb3",
        "filename": "src/nvidia-gpu/NvidiaGpuMctpVdm.cpp",
        "patchSetId": 15
      },
      "lineNbr": 62,
      "author": {
        "id": 1002504
      },
      "writtenOn": "2025-05-27T19:22:23Z",
      "side": 1,
      "message": "nit: missing a const here.",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "c7c15625_51112dc6",
        "filename": "src/nvidia-gpu/NvidiaGpuMctpVdm.cpp",
        "patchSetId": 15
      },
      "lineNbr": 62,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "1c9c9028_d3718bb3",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "0431bb3b_cdf52051",
        "filename": "src/nvidia-gpu/NvidiaGpuMctpVdm.hpp",
        "patchSetId": 15
      },
      "lineNbr": 117,
      "author": {
        "id": 1000056
      },
      "writtenOn": "2025-05-27T17:00:50Z",
      "side": 1,
      "message": "why do we need this here and in the ocp file?",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "05353dca_fd14acf1",
        "filename": "src/nvidia-gpu/NvidiaGpuMctpVdm.hpp",
        "patchSetId": 15
      },
      "lineNbr": 117,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "the one in the ocp file takes pci vendor id as parameter, this one sets it to nvidia vendor it.",
      "parentUuid": "0431bb3b_cdf52051",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "64968110_8ba6243c",
        "filename": "src/nvidia-gpu/NvidiaGpuSensor.cpp",
        "patchSetId": 15
      },
      "lineNbr": 148,
      "author": {
        "id": 1002504
      },
      "writtenOn": "2025-05-27T19:43:45Z",
      "side": 1,
      "message": "nit, and I could go either way on this. having both an error code *and* a std::optional\u003cstd::vector\u003e\u003e of the payload is dual encoding failure modes for no functional reason. Either we have the amount of bytes necessary to decode a response, or we don\u0027t. my preference would be to send an int and a span of bytes, or an optional and take care of your logging on the socket handler side. I\u0027m leaning towards the former, having your client check the error code before using the result is relatively standard, and we haven\u0027t really even solved that problem here, so all we\u0027re doing is convoluting the process more than if we had just given an int and a vector.",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "a157c356_7047620a",
        "filename": "src/nvidia-gpu/NvidiaGpuSensor.cpp",
        "patchSetId": 15
      },
      "lineNbr": 148,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "64968110_8ba6243c",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "030201e3_a50427df",
        "filename": "src/nvidia-gpu/NvidiaGpuSensor.cpp",
        "patchSetId": 15
      },
      "lineNbr": 186,
      "author": {
        "id": 1002504
      },
      "writtenOn": "2025-05-27T19:22:23Z",
      "side": 1,
      "message": "Again, there\u0027s no reason to call new here. We know the message size statically.",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "48fd9afe_14a8f3e4",
        "filename": "src/nvidia-gpu/NvidiaGpuSensor.cpp",
        "patchSetId": 15
      },
      "lineNbr": 186,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "030201e3_a50427df",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "8c906700_7913a6d5",
        "filename": "src/nvidia-gpu/NvidiaGpuSensor.cpp",
        "patchSetId": 15
      },
      "lineNbr": 226,
      "author": {
        "id": 1000056
      },
      "writtenOn": "2025-05-27T17:00:50Z",
      "side": 1,
      "message": "can these be combined?",
      "range": {
        "startLine": 214,
        "startChar": 0,
        "endLine": 226,
        "endChar": 5
      },
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "b292a7cd_24a48ddf",
        "filename": "src/nvidia-gpu/NvidiaGpuSensor.cpp",
        "patchSetId": 15
      },
      "lineNbr": 226,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "Removed.",
      "parentUuid": "8c906700_7913a6d5",
      "range": {
        "startLine": 214,
        "startChar": 0,
        "endLine": 226,
        "endChar": 5
      },
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "4a7697af_3db975f5",
        "filename": "src/nvidia-gpu/NvidiaGpuSensor.cpp",
        "patchSetId": 15
      },
      "lineNbr": 262,
      "author": {
        "id": 1002504
      },
      "writtenOn": "2025-05-27T19:43:45Z",
      "side": 1,
      "message": "We know the size of the request statically, right? no need to invoke dynamic allocation.",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "715f2c98_2a992d76",
        "filename": "src/nvidia-gpu/NvidiaGpuSensor.cpp",
        "patchSetId": 15
      },
      "lineNbr": 262,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "4a7697af_3db975f5",
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9277f608_21aea0ad",
        "filename": "src/nvidia-gpu/NvidiaGpuSensorMain.cpp",
        "patchSetId": 15
      },
      "lineNbr": 67,
      "author": {
        "id": 1000153
      },
      "writtenOn": "2025-05-27T18:05:23Z",
      "side": 1,
      "message": "All of these captures are technically unsafe.  mctpRequester is the first one that actually has lifetime issues.",
      "range": {
        "startLine": 67,
        "startChar": 10,
        "endLine": 67,
        "endChar": 23
      },
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "1213d570_1cbe6107",
        "filename": "src/nvidia-gpu/NvidiaGpuSensorMain.cpp",
        "patchSetId": 15
      },
      "lineNbr": 67,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-30T12:53:12Z",
      "side": 1,
      "message": "Since they are declared within the main function, there will not be lifetime issues.",
      "parentUuid": "9277f608_21aea0ad",
      "range": {
        "startLine": 67,
        "startChar": 10,
        "endLine": 67,
        "endChar": 23
      },
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "de414ee0_51ac470b",
        "filename": "src/nvidia-gpu/OcpMctpVdm.hpp",
        "patchSetId": 15
      },
      "lineNbr": 35,
      "author": {
        "id": 1000056
      },
      "writtenOn": "2025-05-27T17:00:50Z",
      "side": 1,
      "message": "Had this comment on an older patchset - let\u0027s add only what is used in this commit. Same goes for some of the helper functions in this file which are not used anywhere. This will help make the commit concise.",
      "range": {
        "startLine": 27,
        "startChar": 0,
        "endLine": 35,
        "endChar": 46
      },
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "e5513695_4fdf47e4",
        "filename": "src/nvidia-gpu/OcpMctpVdm.hpp",
        "patchSetId": 15
      },
      "lineNbr": 35,
      "author": {
        "id": 1002395
      },
      "writtenOn": "2025-05-28T16:33:52Z",
      "side": 1,
      "message": "All of this definition are being used in source files.",
      "parentUuid": "de414ee0_51ac470b",
      "range": {
        "startLine": 27,
        "startChar": 0,
        "endLine": 35,
        "endChar": 46
      },
      "revId": "2941a94c0b8c28a18f7f4b7917249738d11bd42c",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    }
  ]
}